{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nolYCL2yUcJB",
        "wZGB6ALUcmlo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "e9-_sFsIINFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcbfbfe-daf4-4d80-c98c-c76fda38fbeb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import gc"
      ],
      "metadata": {
        "id": "GRkWd1oRbSJX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_HEIGHT = 32 # RESIZED FIXED HEIGHT\n",
        "IMAGE_WIDTH = 32 # RESIZED FIXED WIDTH\n",
        "NUM_CLASSES = 4 # NUM OF LABELS\n",
        "SEED_VALUE = 1234"
      ],
      "metadata": {
        "id": "D_8fyQ9T_VKL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "random.seed(SEED_VALUE)\n",
        "torch.manual_seed(SEED_VALUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyYIqYN9_D_p",
        "outputId": "9ca06d23-967c-443a-b186-792ea6f8a57d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ca9a52da3f0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "EmtaDieJ_izr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_processed_image_annotations = \"/content/drive/MyDrive/processed_image/train/_annotations.coco.json\"\n",
        "test_processed_image_annotations = \"/content/drive/MyDrive/processed_image/test/_annotations.coco.json\"\n",
        "valid_processed_image_annotations = \"/content/drive/MyDrive/processed_image/valid/_annotations.coco.json\"\n",
        "\n",
        "train_images = \"/content/drive/MyDrive/processed_image/train/\"\n",
        "valid_images = \"/content/drive/MyDrive/processed_image/valid/\"\n",
        "test_images = \"/content/drive/MyDrive/processed_image/test/\""
      ],
      "metadata": {
        "id": "MHSBvpW5hUhW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pd_data(filename) :\n",
        "\n",
        "  json_dict = json.load(open(filename, 'r'))\n",
        "  images = json_dict[\"images\"]\n",
        "  annotations = json_dict[\"annotations\"]\n",
        "\n",
        "  # Convert dictionaries to DataFrames\n",
        "  images_df = pd.DataFrame.from_dict(images)\n",
        "  annotations_df = pd.DataFrame.from_dict(annotations)\n",
        "\n",
        "  # Merge DataFrames based on the common column 'id'\n",
        "  merged_df = pd.merge(images_df, annotations_df, on='id')\n",
        "\n",
        "  return merged_df"
      ],
      "metadata": {
        "id": "BZCs-8xx7mc-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pixels(parent_path, filename):\n",
        "  # return the rgb array\n",
        "  # 1 to indicate no rgb channel. Since its gray-scale we dont need 3 kernels\n",
        "  img = image.load_img(parent_path + filename, color_mode = 'grayscale', target_size = (IMAGE_HEIGHT,IMAGE_WIDTH, 1))\n",
        "  rgb = image.img_to_array(img)\n",
        "  scaled_rgb = rgb/255.0\n",
        "\n",
        "  return scaled_rgb"
      ],
      "metadata": {
        "id": "Afm8hbL10jmh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "nolYCL2yUcJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = get_pd_data(train_processed_image_annotations)\n",
        "valid_df = get_pd_data(valid_processed_image_annotations)"
      ],
      "metadata": {
        "id": "mQov-atf5v2F"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.category_id.value_counts().plot(kind = \"bar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "w_owG3S4UYk0",
        "outputId": "5c6dc75a-0162-4c82-8340-cfc8a1e5fe6c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='category_id'>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Without Augmentation"
      ],
      "metadata": {
        "id": "wZGB6ALUcmlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pixel values to float32 and normalize them\n",
        "X_train = np.array([get_pixels(train_images, x) for x in train_df[\"file_name\"]], dtype=np.float32)\n",
        "y_train = np.array(train_df.category_id - 1)\n",
        "\n",
        "X_val = np.array([get_pixels(valid_images, x) for x in valid_df[\"file_name\"]], dtype=np.float32)\n",
        "y_val = np.array(valid_df.category_id - 1)\n"
      ],
      "metadata": {
        "id": "mum4yLRA3AUe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Release the RAM used to store these dataframes\n",
        "del train_df\n",
        "del valid_df\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHmaqLmDSsSi",
        "outputId": "2c8e1f01-784c-4f5a-e068-36965dbe49b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "38VWhjWLnj5P"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    # Block 1 : Number of filters : 16, kernel size = [3,3], activation = relu Params\n",
        "    # Filter height : 3 , filter width : 3, input channels = 1, since gray scale\n",
        "    # Total num of params for the first block is (3 * 3 )\n",
        "    # Formula : Numfilters * (filter size * filter size * input channel + 1) = 16 * (3*3*1 + 1) = 160 params\n",
        "    # The output shape will be ([Input Size - Filter Size + 2 * Padding] / Stride Size)  + 1\n",
        "    # O = (640 - (3+2*0) / 1 + 1) = 635\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # Block 2 : Number of filters : 16, kernel size = [3,3], activation = relu\n",
        "    Conv2D(16, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # Block 3 : Number of filters : 16, kernel size = [3,3], activation = relu\n",
        "    Conv2D(16, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    # Block 1 : Number of filters : 16, kernel size = [1], activation = relu\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(NUM_CLASSES, activation='softmax') # Last layer to classify the multiclassification problem\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5I7z2fkkuaO4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "533e0ds5Yk3t",
        "outputId": "54b95be3-2b40-48ff-d299-23016614cc14"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuxY8WyPu_QW",
        "outputId": "e0393f37-3db6-4a3d-c84d-5e7637cfcf7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 241s 10s/step - loss: 1.3738 - accuracy: 0.3960 - val_loss: 2.0393 - val_accuracy: 0.1308\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 261s 11s/step - loss: 1.0329 - accuracy: 0.5865 - val_loss: 2.7952 - val_accuracy: 0.1519\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 259s 10s/step - loss: 0.8662 - accuracy: 0.6278 - val_loss: 2.5193 - val_accuracy: 0.1941\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 271s 11s/step - loss: 0.6210 - accuracy: 0.7657 - val_loss: 2.2040 - val_accuracy: 0.1772\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 247s 10s/step - loss: 0.4874 - accuracy: 0.8195 - val_loss: 3.4923 - val_accuracy: 0.2700\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 255s 10s/step - loss: 0.3207 - accuracy: 0.8897 - val_loss: 3.8382 - val_accuracy: 0.2489\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 279s 11s/step - loss: 0.2133 - accuracy: 0.9261 - val_loss: 5.1509 - val_accuracy: 0.2700\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 274s 11s/step - loss: 0.1519 - accuracy: 0.9549 - val_loss: 5.8057 - val_accuracy: 0.2025\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 276s 11s/step - loss: 0.1034 - accuracy: 0.9687 - val_loss: 6.5997 - val_accuracy: 0.2785\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 262s 11s/step - loss: 0.0614 - accuracy: 0.9825 - val_loss: 7.0125 - val_accuracy: 0.1983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model might be overfitting due to high training accuracy but low validation accuracy. This might be due to prescence of imbalanced nature of our dataset"
      ],
      "metadata": {
        "id": "YC03yFZ_Qxt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cnn_no_augment.hd5')"
      ],
      "metadata": {
        "id": "pzJflvxFR1LH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model(\"/content/drive/MyDrive/cnn_no_augment.hd5\")\n"
      ],
      "metadata": {
        "id": "vqSNj0mlSqua"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train\n",
        "del X_val\n",
        "del y_train\n",
        "del y_val\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "OS56q8KhAHFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8792c7c-e3a4-4a13-a66a-6efd4b805a89"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22998"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = get_pd_data(test_processed_image_annotations)"
      ],
      "metadata": {
        "id": "8gT7gj6NZ1w-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([get_pixels(test_images, x) for x in test_df[\"file_name\"]], dtype=np.float32)\n",
        "y_test = np.array(test_df.category_id)"
      ],
      "metadata": {
        "id": "6v75ef9CZ59w"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = loaded_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO3XoKcTaCK2",
        "outputId": "858a7a95-d820-4416-f820-14e3932a9925"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 10s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give me the code to get the classification report of predict vs test\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get the predicted labels\n",
        "predicted_labels = np.argmax(result, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "\n",
        "# Print the report\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHHOtu-HaHkC",
        "outputId": "523f3558-f4a4-4004-ed35-6ce64f5f31f0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.11      0.24      0.15        17\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.75      0.10      0.18        30\n",
            "           4       0.00      0.00      0.00        67\n",
            "\n",
            "    accuracy                           0.06       125\n",
            "   macro avg       0.17      0.07      0.07       125\n",
            "weighted avg       0.20      0.06      0.06       125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation to Improve Model"
      ],
      "metadata": {
        "id": "3XyuQ0NvQ_MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imgaug.augmenters as iaa"
      ],
      "metadata": {
        "id": "7nv4kN6EUE5x"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = get_pd_data(train_processed_image_annotations)\n",
        "valid_df = get_pd_data(valid_processed_image_annotations)"
      ],
      "metadata": {
        "id": "l675cbDwb-Ie"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pixel values to float32 and normalize them\n",
        "X_train = np.array([get_pixels(train_images, x) for x in train_df[\"file_name\"]], dtype=np.float32)\n",
        "y_train = np.array(train_df.category_id - 1)\n",
        "\n",
        "X_val = np.array([get_pixels(valid_images, x) for x in valid_df[\"file_name\"]], dtype=np.float32)\n",
        "y_val = np.array(valid_df.category_id - 1)"
      ],
      "metadata": {
        "id": "fVPgL18CcEj4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Release the RAM used to store these dataframes\n",
        "del train_df\n",
        "del valid_df\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wybSmyH1cFXp",
        "outputId": "8dfb4f2f-bf93-4f1b-ff16-ab00b4cf5ab6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since our data is gray scaled, we can only use these augmentations\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Crop(percent=(0, 0.1)),\n",
        "    iaa.GaussianBlur(sigma=(0.0, 3.0)),  # Gaussian blur with random sigma\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.05 * 255)),  # Add Gaussian noise\n",
        "    iaa.Affine(rotate=(-45, 45)),  # Random rotation between -45 and 45 degrees\n",
        "    iaa.ShearX((-20, 20)),  # Shear along the x-axis\n",
        "    iaa.ContrastNormalization((0.5, 1.5)),  # Contrast normalization\n",
        "    iaa.Multiply((0.5, 1.5), per_channel=0.5),  # Multiply pixel values (brightness)\n",
        "], random_order=True)"
      ],
      "metadata": {
        "id": "aII3X4PGUHJd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# Define augmentation sequence\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Crop(percent=(0, 0.1)),\n",
        "    iaa.GaussianBlur(sigma=(0.0, 3.0)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.05 * 255)),\n",
        "    iaa.Affine(rotate=(-45, 45)),\n",
        "    iaa.ShearX((-20, 20)),\n",
        "    iaa.ContrastNormalization((0.5, 1.5)),\n",
        "    iaa.Multiply((0.5, 1.5), per_channel=0.5)\n",
        "], random_order=True)\n",
        "\n",
        "# Find unique values and their counts\n",
        "unique_values, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "# Find the index of the maximum count\n",
        "max_count_index = np.argmax(counts)\n",
        "\n",
        "# Get the class ID with the maximum count\n",
        "class_with_max_count = unique_values[max_count_index]\n",
        "\n",
        "# Get the maximum count\n",
        "max_count = counts[max_count_index]\n",
        "\n",
        "augmented_X_train = []\n",
        "augmented_y_train = []\n",
        "\n",
        "# Include all samples from the class with the maximum count in augmented_X_train and augmented_y_train\n",
        "max_count_indices = np.where(y_train == class_with_max_count)[0]\n",
        "max_count_images = X_train[max_count_indices]\n",
        "augmented_X_train.extend(max_count_images)\n",
        "augmented_y_train.extend([class_with_max_count] * len(max_count_images))\n",
        "\n",
        "# Loop through each class\n",
        "for cls in unique_values:\n",
        "    # Skip the class with the maximum count\n",
        "    if cls == class_with_max_count:\n",
        "        continue\n",
        "\n",
        "    # Select images belonging to the minority class\n",
        "    minority_indices = np.where(y_train == cls)[0]\n",
        "    minority_images = X_train[minority_indices]\n",
        "\n",
        "    # Calculate the number of samples to augment\n",
        "    num_to_augment = max_count - len(minority_images)\n",
        "\n",
        "    # Select random samples from the minority class for augmentation\n",
        "    selected_indices = np.random.choice(minority_indices, size=num_to_augment, replace=True)\n",
        "    selected_images = X_train[selected_indices]\n",
        "\n",
        "    # Augment selected images\n",
        "    augmented_images = [seq.augment_image(img) for img in selected_images]\n",
        "\n",
        "    # Append augmented data to the lists\n",
        "    augmented_X_train.extend(augmented_images)\n",
        "    augmented_X_train.extend(minority_images)\n",
        "\n",
        "    # Append labels\n",
        "    augmented_y_train.extend([cls] * len(augmented_images))\n",
        "    augmented_y_train.extend([cls] * len(minority_images))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "augmented_X_train = np.array(augmented_X_train)\n",
        "augmented_y_train = np.array(augmented_y_train)\n",
        "\n",
        "# Shuffle augmented data\n",
        "shuffle_indices = np.random.permutation(len(augmented_X_train))\n",
        "augmented_X_train = augmented_X_train[shuffle_indices]\n",
        "augmented_y_train = augmented_y_train[shuffle_indices]\n"
      ],
      "metadata": {
        "id": "2B-YgOFGWJgQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(augmented_y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxURfRz5bA7W",
        "outputId": "e161680d-7a58-48b2-cd88-85130d400f6f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1284"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del seq\n",
        "del X_train\n",
        "del y_train\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npGzncOQcaxl",
        "outputId": "12838955-2df3-4916-ef4c-04e1649b7d0c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # Block 1 : Number of filters : 16, kernel size = [3,3], activation = relu Params\n",
        "    # Filter height : 3 , filter width : 3, input channels = 1, since gray scale\n",
        "    # Total num of params for the first block is (3 * 3 )\n",
        "    # Formula : Numfilters * (filter size * filter size * input channel + 1) = 16 * (3*3*1 + 1) = 160 params\n",
        "    # The output shape will be ([Input Size - Filter Size + 2 * Padding] / Stride Size)  + 1\n",
        "    # O = (640 - (3+2*0) / 1 + 1) = 635\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # Block 2 : Number of filters : 16, kernel size = [3,3], activation = relu\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    # Block 3 : Number of filters : 16, kernel size = [3,3], activation = relu\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    # Block 1 : Number of filters : 16, kernel size = [1], activation = relu\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(NUM_CLASSES, activation='softmax') # Last layer to classify the multiclassification problem\n",
        "])"
      ],
      "metadata": {
        "id": "Er8t7_Jjapb-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rLjfHPeFbSaC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF54nZJjbbTo",
        "outputId": "6db47df6-f4b4-4ad1-dd42-76976d081f08"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 32)          9248      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                8208      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36628 (143.08 KB)\n",
            "Trainable params: 36628 (143.08 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 60\n",
        "epochs = 200\n",
        "history = model.fit(augmented_X_train, augmented_y_train, steps_per_epoch = len(augmented_y_train)// batch_size,\n",
        "    epochs = epochs, validation_data=(X_val, y_val),\n",
        "    callbacks = [EarlyStopping()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Ey3QBscuFQ",
        "outputId": "a2fdcf95-7fdb-43da-f916-84c0a50c0e72"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "21/21 [==============================] - 6s 272ms/step - loss: 0.4597 - accuracy: 0.8107 - val_loss: 2.1109 - val_accuracy: 0.3671\n",
            "Epoch 2/200\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.4167 - accuracy: 0.8403 - val_loss: 2.5532 - val_accuracy: 0.2110\n",
            "Epoch 3/200\n",
            "21/21 [==============================] - 2s 91ms/step - loss: 0.4265 - accuracy: 0.8333 - val_loss: 2.3946 - val_accuracy: 0.2954\n",
            "Epoch 4/200\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.4314 - accuracy: 0.8341 - val_loss: 2.7467 - val_accuracy: 0.2532\n",
            "Epoch 5/200\n",
            "21/21 [==============================] - 2s 90ms/step - loss: 0.4145 - accuracy: 0.8302 - val_loss: 2.6989 - val_accuracy: 0.2743\n",
            "Epoch 6/200\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.3935 - accuracy: 0.8388 - val_loss: 3.0372 - val_accuracy: 0.2785\n",
            "Epoch 7/200\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.3823 - accuracy: 0.8450 - val_loss: 2.6517 - val_accuracy: 0.2700\n",
            "Epoch 8/200\n",
            "21/21 [==============================] - 2s 89ms/step - loss: 0.3691 - accuracy: 0.8458 - val_loss: 2.6311 - val_accuracy: 0.3165\n",
            "Epoch 9/200\n",
            "21/21 [==============================] - 2s 89ms/step - loss: 0.3422 - accuracy: 0.8684 - val_loss: 2.2997 - val_accuracy: 0.3249\n",
            "Epoch 10/200\n",
            "21/21 [==============================] - 2s 92ms/step - loss: 0.3327 - accuracy: 0.8769 - val_loss: 2.6671 - val_accuracy: 0.3249\n",
            "Epoch 11/200\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.3522 - accuracy: 0.8575 - val_loss: 2.6406 - val_accuracy: 0.3460\n",
            "Epoch 12/200\n",
            "21/21 [==============================] - 4s 203ms/step - loss: 0.3563 - accuracy: 0.8621 - val_loss: 2.9080 - val_accuracy: 0.1814\n",
            "Epoch 13/200\n",
            "21/21 [==============================] - 4s 208ms/step - loss: 0.3338 - accuracy: 0.8692 - val_loss: 2.2716 - val_accuracy: 0.2996\n",
            "Epoch 14/200\n",
            "21/21 [==============================] - 4s 196ms/step - loss: 0.3012 - accuracy: 0.8972 - val_loss: 2.5935 - val_accuracy: 0.2954\n",
            "Epoch 15/200\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.2993 - accuracy: 0.8886 - val_loss: 2.8851 - val_accuracy: 0.2658\n",
            "Epoch 16/200\n",
            "21/21 [==============================] - 4s 212ms/step - loss: 0.2806 - accuracy: 0.8894 - val_loss: 2.8731 - val_accuracy: 0.3207\n",
            "Epoch 17/200\n",
            "21/21 [==============================] - 4s 189ms/step - loss: 0.2704 - accuracy: 0.8972 - val_loss: 2.7840 - val_accuracy: 0.2827\n",
            "Epoch 18/200\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.2652 - accuracy: 0.9050 - val_loss: 2.9186 - val_accuracy: 0.2743\n",
            "Epoch 19/200\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2638 - accuracy: 0.9050 - val_loss: 2.8212 - val_accuracy: 0.3333\n",
            "Epoch 20/200\n",
            "21/21 [==============================] - 5s 223ms/step - loss: 0.2461 - accuracy: 0.9167 - val_loss: 2.7673 - val_accuracy: 0.3249\n",
            "Epoch 21/200\n",
            "21/21 [==============================] - 3s 151ms/step - loss: 0.2550 - accuracy: 0.9151 - val_loss: 3.0795 - val_accuracy: 0.2278\n",
            "Epoch 22/200\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.4475 - accuracy: 0.8427 - val_loss: 2.4151 - val_accuracy: 0.3502\n",
            "Epoch 23/200\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.3164 - accuracy: 0.8785 - val_loss: 2.4751 - val_accuracy: 0.2616\n",
            "Epoch 24/200\n",
            "21/21 [==============================] - 5s 244ms/step - loss: 0.2532 - accuracy: 0.9167 - val_loss: 3.0661 - val_accuracy: 0.2869\n",
            "Epoch 25/200\n",
            "21/21 [==============================] - 4s 204ms/step - loss: 0.2386 - accuracy: 0.9128 - val_loss: 2.9583 - val_accuracy: 0.3376\n",
            "Epoch 26/200\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2155 - accuracy: 0.9245 - val_loss: 2.5677 - val_accuracy: 0.3165\n",
            "Epoch 27/200\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.2105 - accuracy: 0.9400 - val_loss: 3.1464 - val_accuracy: 0.2911\n",
            "Epoch 28/200\n",
            "21/21 [==============================] - 4s 210ms/step - loss: 0.1988 - accuracy: 0.9361 - val_loss: 3.1346 - val_accuracy: 0.3418\n",
            "Epoch 29/200\n",
            "21/21 [==============================] - 6s 265ms/step - loss: 0.1874 - accuracy: 0.9400 - val_loss: 3.3686 - val_accuracy: 0.3080\n",
            "Epoch 30/200\n",
            "21/21 [==============================] - 5s 225ms/step - loss: 0.1835 - accuracy: 0.9424 - val_loss: 3.4946 - val_accuracy: 0.3291\n",
            "Epoch 31/200\n",
            "21/21 [==============================] - 5s 259ms/step - loss: 0.1899 - accuracy: 0.9346 - val_loss: 3.5289 - val_accuracy: 0.2194\n",
            "Epoch 32/200\n",
            "21/21 [==============================] - 5s 259ms/step - loss: 0.1851 - accuracy: 0.9369 - val_loss: 3.3832 - val_accuracy: 0.3418\n",
            "Epoch 33/200\n",
            "21/21 [==============================] - 4s 186ms/step - loss: 0.1945 - accuracy: 0.9237 - val_loss: 3.5387 - val_accuracy: 0.3165\n",
            "Epoch 34/200\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1641 - accuracy: 0.9439 - val_loss: 3.4034 - val_accuracy: 0.3165\n",
            "Epoch 35/200\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1498 - accuracy: 0.9579 - val_loss: 3.7496 - val_accuracy: 0.3165\n",
            "Epoch 36/200\n",
            "21/21 [==============================] - 4s 188ms/step - loss: 0.1405 - accuracy: 0.9595 - val_loss: 3.3873 - val_accuracy: 0.3460\n",
            "Epoch 37/200\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.1399 - accuracy: 0.9564 - val_loss: 3.5587 - val_accuracy: 0.2911\n",
            "Epoch 38/200\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.1306 - accuracy: 0.9657 - val_loss: 3.4908 - val_accuracy: 0.3165\n",
            "Epoch 39/200\n",
            "21/21 [==============================] - 5s 226ms/step - loss: 0.1193 - accuracy: 0.9688 - val_loss: 3.3085 - val_accuracy: 0.3207\n",
            "Epoch 40/200\n",
            "21/21 [==============================] - 5s 238ms/step - loss: 0.1423 - accuracy: 0.9502 - val_loss: 3.6204 - val_accuracy: 0.2616\n",
            "Epoch 41/200\n",
            "21/21 [==============================] - 3s 159ms/step - loss: 0.1745 - accuracy: 0.9470 - val_loss: 3.4594 - val_accuracy: 0.3291\n",
            "Epoch 42/200\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.2934 - accuracy: 0.9120 - val_loss: 3.8029 - val_accuracy: 0.3671\n",
            "Epoch 43/200\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.2162 - accuracy: 0.9307 - val_loss: 3.0254 - val_accuracy: 0.3586\n",
            "Epoch 44/200\n",
            "21/21 [==============================] - 6s 303ms/step - loss: 0.1572 - accuracy: 0.9509 - val_loss: 3.5423 - val_accuracy: 0.3544\n",
            "Epoch 45/200\n",
            "21/21 [==============================] - 6s 265ms/step - loss: 0.1250 - accuracy: 0.9704 - val_loss: 3.9229 - val_accuracy: 0.2996\n",
            "Epoch 46/200\n",
            "21/21 [==============================] - 5s 219ms/step - loss: 0.1245 - accuracy: 0.9603 - val_loss: 3.3801 - val_accuracy: 0.2996\n",
            "Epoch 47/200\n",
            "21/21 [==============================] - 4s 216ms/step - loss: 0.1122 - accuracy: 0.9657 - val_loss: 4.0282 - val_accuracy: 0.2616\n",
            "Epoch 48/200\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 0.1075 - accuracy: 0.9673 - val_loss: 3.5596 - val_accuracy: 0.3249\n",
            "Epoch 49/200\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1073 - accuracy: 0.9681 - val_loss: 3.9453 - val_accuracy: 0.2954\n",
            "Epoch 50/200\n",
            "21/21 [==============================] - 2s 90ms/step - loss: 0.0864 - accuracy: 0.9798 - val_loss: 4.3676 - val_accuracy: 0.2532\n",
            "Epoch 51/200\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.0991 - accuracy: 0.9696 - val_loss: 3.9177 - val_accuracy: 0.2827\n",
            "Epoch 52/200\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.0792 - accuracy: 0.9805 - val_loss: 3.9409 - val_accuracy: 0.3333\n",
            "Epoch 53/200\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.0762 - accuracy: 0.9805 - val_loss: 3.9814 - val_accuracy: 0.2954\n",
            "Epoch 54/200\n",
            "21/21 [==============================] - 2s 94ms/step - loss: 0.0706 - accuracy: 0.9829 - val_loss: 4.6147 - val_accuracy: 0.3038\n",
            "Epoch 55/200\n",
            "21/21 [==============================] - 2s 96ms/step - loss: 0.0696 - accuracy: 0.9813 - val_loss: 3.8830 - val_accuracy: 0.3122\n",
            "Epoch 56/200\n",
            "21/21 [==============================] - 2s 93ms/step - loss: 0.0671 - accuracy: 0.9836 - val_loss: 4.1830 - val_accuracy: 0.3418\n",
            "Epoch 57/200\n",
            "21/21 [==============================] - 2s 95ms/step - loss: 0.0698 - accuracy: 0.9798 - val_loss: 4.2089 - val_accuracy: 0.3207\n",
            "Epoch 58/200\n",
            "21/21 [==============================] - 2s 104ms/step - loss: 0.0577 - accuracy: 0.9891 - val_loss: 4.7596 - val_accuracy: 0.2996\n",
            "Epoch 59/200\n",
            "21/21 [==============================] - 3s 157ms/step - loss: 0.0655 - accuracy: 0.9813 - val_loss: 4.4393 - val_accuracy: 0.2996\n",
            "Epoch 60/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.0581 - accuracy: 0.9836 - val_loss: 4.5705 - val_accuracy: 0.3713\n",
            "Epoch 61/200\n",
            "21/21 [==============================] - 2s 93ms/step - loss: 0.0603 - accuracy: 0.9821 - val_loss: 4.3440 - val_accuracy: 0.3165\n",
            "Epoch 62/200\n",
            "21/21 [==============================] - 2s 93ms/step - loss: 0.0552 - accuracy: 0.9875 - val_loss: 4.5284 - val_accuracy: 0.2911\n",
            "Epoch 63/200\n",
            "21/21 [==============================] - 2s 94ms/step - loss: 0.0775 - accuracy: 0.9735 - val_loss: 4.8043 - val_accuracy: 0.2700\n",
            "Epoch 64/200\n",
            "21/21 [==============================] - 2s 94ms/step - loss: 0.0589 - accuracy: 0.9868 - val_loss: 4.7519 - val_accuracy: 0.2954\n",
            "Epoch 65/200\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.0478 - accuracy: 0.9875 - val_loss: 4.6357 - val_accuracy: 0.3333\n",
            "Epoch 66/200\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0440 - accuracy: 0.9922 - val_loss: 4.5762 - val_accuracy: 0.3544\n",
            "Epoch 67/200\n",
            "21/21 [==============================] - 2s 90ms/step - loss: 0.0434 - accuracy: 0.9922 - val_loss: 4.5983 - val_accuracy: 0.3291\n",
            "Epoch 68/200\n",
            "21/21 [==============================] - 2s 92ms/step - loss: 0.0387 - accuracy: 0.9907 - val_loss: 4.7531 - val_accuracy: 0.3165\n",
            "Epoch 69/200\n",
            "21/21 [==============================] - 2s 92ms/step - loss: 0.0422 - accuracy: 0.9914 - val_loss: 4.7631 - val_accuracy: 0.3376\n",
            "Epoch 70/200\n",
            "21/21 [==============================] - 2s 96ms/step - loss: 0.0473 - accuracy: 0.9891 - val_loss: 4.8947 - val_accuracy: 0.3249\n",
            "Epoch 71/200\n",
            "21/21 [==============================] - 2s 108ms/step - loss: 0.0452 - accuracy: 0.9860 - val_loss: 5.0691 - val_accuracy: 0.2869\n",
            "Epoch 72/200\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.0436 - accuracy: 0.9922 - val_loss: 5.8067 - val_accuracy: 0.2574\n",
            "Epoch 73/200\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.0432 - accuracy: 0.9875 - val_loss: 5.4291 - val_accuracy: 0.3333\n",
            "Epoch 74/200\n",
            "21/21 [==============================] - 2s 94ms/step - loss: 0.0460 - accuracy: 0.9868 - val_loss: 5.2429 - val_accuracy: 0.3333\n",
            "Epoch 75/200\n",
            "21/21 [==============================] - 2s 95ms/step - loss: 0.0374 - accuracy: 0.9907 - val_loss: 5.2896 - val_accuracy: 0.3038\n",
            "Epoch 76/200\n",
            "21/21 [==============================] - 2s 98ms/step - loss: 0.0318 - accuracy: 0.9938 - val_loss: 5.2645 - val_accuracy: 0.3207\n",
            "Epoch 77/200\n",
            "21/21 [==============================] - 2s 108ms/step - loss: 0.0284 - accuracy: 0.9953 - val_loss: 5.2614 - val_accuracy: 0.2996\n",
            "Epoch 78/200\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0304 - accuracy: 0.9945 - val_loss: 5.8511 - val_accuracy: 0.3080\n",
            "Epoch 79/200\n",
            "21/21 [==============================] - 2s 108ms/step - loss: 0.0308 - accuracy: 0.9914 - val_loss: 5.2930 - val_accuracy: 0.3333\n",
            "Epoch 80/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0297 - accuracy: 0.9945 - val_loss: 5.2993 - val_accuracy: 0.3502\n",
            "Epoch 81/200\n",
            "21/21 [==============================] - 2s 101ms/step - loss: 0.0249 - accuracy: 0.9953 - val_loss: 5.6628 - val_accuracy: 0.3038\n",
            "Epoch 82/200\n",
            "21/21 [==============================] - 2s 99ms/step - loss: 0.0248 - accuracy: 0.9969 - val_loss: 5.9484 - val_accuracy: 0.3122\n",
            "Epoch 83/200\n",
            "21/21 [==============================] - 2s 96ms/step - loss: 0.0240 - accuracy: 0.9953 - val_loss: 5.9807 - val_accuracy: 0.2911\n",
            "Epoch 84/200\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.0232 - accuracy: 0.9953 - val_loss: 5.7141 - val_accuracy: 0.3249\n",
            "Epoch 85/200\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0210 - accuracy: 0.9992 - val_loss: 5.7561 - val_accuracy: 0.3460\n",
            "Epoch 86/200\n",
            "21/21 [==============================] - 2s 110ms/step - loss: 0.0205 - accuracy: 0.9977 - val_loss: 5.9090 - val_accuracy: 0.3207\n",
            "Epoch 87/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.0183 - accuracy: 0.9977 - val_loss: 6.3330 - val_accuracy: 0.3122\n",
            "Epoch 88/200\n",
            "21/21 [==============================] - 2s 96ms/step - loss: 0.0164 - accuracy: 0.9992 - val_loss: 5.9840 - val_accuracy: 0.2996\n",
            "Epoch 89/200\n",
            "21/21 [==============================] - 2s 107ms/step - loss: 0.0162 - accuracy: 0.9977 - val_loss: 6.2320 - val_accuracy: 0.3038\n",
            "Epoch 90/200\n",
            "21/21 [==============================] - 4s 169ms/step - loss: 0.0179 - accuracy: 0.9992 - val_loss: 6.0779 - val_accuracy: 0.3418\n",
            "Epoch 91/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 5.8555 - val_accuracy: 0.3038\n",
            "Epoch 92/200\n",
            "21/21 [==============================] - 2s 94ms/step - loss: 0.0146 - accuracy: 0.9992 - val_loss: 6.3383 - val_accuracy: 0.3122\n",
            "Epoch 93/200\n",
            "21/21 [==============================] - 2s 94ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 6.4736 - val_accuracy: 0.3080\n",
            "Epoch 94/200\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0143 - accuracy: 0.9992 - val_loss: 6.4325 - val_accuracy: 0.3165\n",
            "Epoch 95/200\n",
            "21/21 [==============================] - 4s 186ms/step - loss: 0.0122 - accuracy: 0.9992 - val_loss: 6.4124 - val_accuracy: 0.3418\n",
            "Epoch 96/200\n",
            "21/21 [==============================] - 4s 185ms/step - loss: 0.0141 - accuracy: 0.9992 - val_loss: 6.4727 - val_accuracy: 0.3502\n",
            "Epoch 97/200\n",
            "21/21 [==============================] - 2s 93ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 6.3033 - val_accuracy: 0.3249\n",
            "Epoch 98/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 6.2381 - val_accuracy: 0.3418\n",
            "Epoch 99/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 6.4957 - val_accuracy: 0.3122\n",
            "Epoch 100/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 6.7034 - val_accuracy: 0.2954\n",
            "Epoch 101/200\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 6.6221 - val_accuracy: 0.3122\n",
            "Epoch 102/200\n",
            "21/21 [==============================] - 4s 170ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 6.6649 - val_accuracy: 0.3291\n",
            "Epoch 103/200\n",
            "21/21 [==============================] - 3s 166ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 6.6557 - val_accuracy: 0.3080\n",
            "Epoch 104/200\n",
            "21/21 [==============================] - 2s 99ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 6.7158 - val_accuracy: 0.3333\n",
            "Epoch 105/200\n",
            "21/21 [==============================] - 2s 101ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 6.4089 - val_accuracy: 0.3165\n",
            "Epoch 106/200\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 7.0557 - val_accuracy: 0.3038\n",
            "Epoch 107/200\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 6.8475 - val_accuracy: 0.3080\n",
            "Epoch 108/200\n",
            "21/21 [==============================] - 3s 151ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 6.7647 - val_accuracy: 0.3122\n",
            "Epoch 109/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 0.0114 - accuracy: 0.9992 - val_loss: 6.5554 - val_accuracy: 0.3418\n",
            "Epoch 110/200\n",
            "21/21 [==============================] - 2s 99ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 7.0017 - val_accuracy: 0.3080\n",
            "Epoch 111/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 6.9079 - val_accuracy: 0.3291\n",
            "Epoch 112/200\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 6.9566 - val_accuracy: 0.3418\n",
            "Epoch 113/200\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 6.9999 - val_accuracy: 0.3122\n",
            "Epoch 114/200\n",
            "21/21 [==============================] - 3s 157ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 7.1500 - val_accuracy: 0.3291\n",
            "Epoch 115/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 7.0893 - val_accuracy: 0.3165\n",
            "Epoch 116/200\n",
            "21/21 [==============================] - 2s 107ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 7.3459 - val_accuracy: 0.3249\n",
            "Epoch 117/200\n",
            "21/21 [==============================] - 2s 105ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 7.2160 - val_accuracy: 0.3249\n",
            "Epoch 118/200\n",
            "21/21 [==============================] - 2s 111ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 7.3548 - val_accuracy: 0.3249\n",
            "Epoch 119/200\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 7.4468 - val_accuracy: 0.3207\n",
            "Epoch 120/200\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 7.3378 - val_accuracy: 0.3291\n",
            "Epoch 121/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 7.4623 - val_accuracy: 0.3249\n",
            "Epoch 122/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 7.3175 - val_accuracy: 0.3418\n",
            "Epoch 123/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 7.5663 - val_accuracy: 0.3165\n",
            "Epoch 124/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 7.1931 - val_accuracy: 0.3460\n",
            "Epoch 125/200\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 7.5605 - val_accuracy: 0.3207\n",
            "Epoch 126/200\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 7.3794 - val_accuracy: 0.3333\n",
            "Epoch 127/200\n",
            "21/21 [==============================] - 2s 101ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 7.5597 - val_accuracy: 0.3333\n",
            "Epoch 128/200\n",
            "21/21 [==============================] - 2s 105ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 7.5157 - val_accuracy: 0.3249\n",
            "Epoch 129/200\n",
            "21/21 [==============================] - 2s 101ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 7.6690 - val_accuracy: 0.3207\n",
            "Epoch 130/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.3376\n",
            "Epoch 131/200\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 7.6780 - val_accuracy: 0.3376\n",
            "Epoch 132/200\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.8063 - val_accuracy: 0.3291\n",
            "Epoch 133/200\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 8.0432 - val_accuracy: 0.3122\n",
            "Epoch 134/200\n",
            "21/21 [==============================] - 4s 193ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 7.7395 - val_accuracy: 0.3291\n",
            "Epoch 135/200\n",
            "21/21 [==============================] - 5s 226ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 7.7329 - val_accuracy: 0.3291\n",
            "Epoch 136/200\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 7.7674 - val_accuracy: 0.3291\n",
            "Epoch 137/200\n",
            "21/21 [==============================] - 2s 106ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 8.0314 - val_accuracy: 0.3291\n",
            "Epoch 138/200\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 8.0138 - val_accuracy: 0.3291\n",
            "Epoch 139/200\n",
            "21/21 [==============================] - 2s 96ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 7.9703 - val_accuracy: 0.3291\n",
            "Epoch 140/200\n",
            "21/21 [==============================] - 2s 114ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 7.8432 - val_accuracy: 0.3291\n",
            "Epoch 141/200\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 7.9508 - val_accuracy: 0.3249\n",
            "Epoch 142/200\n",
            "21/21 [==============================] - 2s 109ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.9758 - val_accuracy: 0.3460\n",
            "Epoch 143/200\n",
            "21/21 [==============================] - 2s 106ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 8.2710 - val_accuracy: 0.3207\n",
            "Epoch 144/200\n",
            "21/21 [==============================] - 2s 109ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 8.1935 - val_accuracy: 0.3333\n",
            "Epoch 145/200\n",
            "21/21 [==============================] - 2s 104ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 8.3155 - val_accuracy: 0.3165\n",
            "Epoch 146/200\n",
            "21/21 [==============================] - 2s 116ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 8.0857 - val_accuracy: 0.3418\n",
            "Epoch 147/200\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 8.2084 - val_accuracy: 0.3418\n",
            "Epoch 148/200\n",
            "21/21 [==============================] - 2s 99ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.0677 - val_accuracy: 0.3333\n",
            "Epoch 149/200\n",
            "21/21 [==============================] - 2s 95ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.3510 - val_accuracy: 0.3418\n",
            "Epoch 150/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.3858 - val_accuracy: 0.3249\n",
            "Epoch 151/200\n",
            "21/21 [==============================] - 2s 95ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.3789 - val_accuracy: 0.3207\n",
            "Epoch 152/200\n",
            "21/21 [==============================] - 2s 105ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 8.4963 - val_accuracy: 0.3249\n",
            "Epoch 153/200\n",
            "21/21 [==============================] - 3s 163ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.5526 - val_accuracy: 0.3249\n",
            "Epoch 154/200\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.3728 - val_accuracy: 0.3333\n",
            "Epoch 155/200\n",
            "21/21 [==============================] - 2s 99ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.6966 - val_accuracy: 0.3207\n",
            "Epoch 156/200\n",
            "21/21 [==============================] - 2s 104ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 8.4619 - val_accuracy: 0.3376\n",
            "Epoch 157/200\n",
            "21/21 [==============================] - 2s 106ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.4600 - val_accuracy: 0.3291\n",
            "Epoch 158/200\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.6023 - val_accuracy: 0.3333\n",
            "Epoch 159/200\n",
            "21/21 [==============================] - 4s 168ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.4082 - val_accuracy: 0.3460\n",
            "Epoch 160/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.6555 - val_accuracy: 0.3207\n",
            "Epoch 161/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.6185 - val_accuracy: 0.3291\n",
            "Epoch 162/200\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.5565 - val_accuracy: 0.3333\n",
            "Epoch 163/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.6691 - val_accuracy: 0.3291\n",
            "Epoch 164/200\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.7620 - val_accuracy: 0.3207\n",
            "Epoch 165/200\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.6477 - val_accuracy: 0.3333\n",
            "Epoch 166/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.6522 - val_accuracy: 0.3291\n",
            "Epoch 167/200\n",
            "21/21 [==============================] - 2s 107ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.8113 - val_accuracy: 0.3249\n",
            "Epoch 168/200\n",
            "21/21 [==============================] - 2s 98ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.7915 - val_accuracy: 0.3249\n",
            "Epoch 169/200\n",
            "21/21 [==============================] - 2s 101ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.0327 - val_accuracy: 0.3165\n",
            "Epoch 170/200\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.7920 - val_accuracy: 0.3333\n",
            "Epoch 171/200\n",
            "21/21 [==============================] - 4s 196ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.7724 - val_accuracy: 0.3418\n",
            "Epoch 172/200\n",
            "21/21 [==============================] - 2s 105ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.9567 - val_accuracy: 0.3249\n",
            "Epoch 173/200\n",
            "21/21 [==============================] - 2s 101ms/step - loss: 9.8527e-04 - accuracy: 1.0000 - val_loss: 8.8119 - val_accuracy: 0.3333\n",
            "Epoch 174/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.8108 - val_accuracy: 0.3333\n",
            "Epoch 175/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 9.4561e-04 - accuracy: 1.0000 - val_loss: 9.0530 - val_accuracy: 0.3291\n",
            "Epoch 176/200\n",
            "21/21 [==============================] - 2s 116ms/step - loss: 9.2967e-04 - accuracy: 1.0000 - val_loss: 8.9266 - val_accuracy: 0.3376\n",
            "Epoch 177/200\n",
            "21/21 [==============================] - 3s 165ms/step - loss: 9.0451e-04 - accuracy: 1.0000 - val_loss: 9.0115 - val_accuracy: 0.3291\n",
            "Epoch 178/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 8.7646e-04 - accuracy: 1.0000 - val_loss: 8.9150 - val_accuracy: 0.3376\n",
            "Epoch 179/200\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 8.7337e-04 - accuracy: 1.0000 - val_loss: 9.0706 - val_accuracy: 0.3291\n",
            "Epoch 180/200\n",
            "21/21 [==============================] - 2s 105ms/step - loss: 8.7410e-04 - accuracy: 1.0000 - val_loss: 9.0690 - val_accuracy: 0.3376\n",
            "Epoch 181/200\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 8.3053e-04 - accuracy: 1.0000 - val_loss: 9.0574 - val_accuracy: 0.3291\n",
            "Epoch 182/200\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 7.9145e-04 - accuracy: 1.0000 - val_loss: 9.1117 - val_accuracy: 0.3333\n",
            "Epoch 183/200\n",
            "21/21 [==============================] - 4s 167ms/step - loss: 7.9554e-04 - accuracy: 1.0000 - val_loss: 9.1752 - val_accuracy: 0.3333\n",
            "Epoch 184/200\n",
            "21/21 [==============================] - 2s 105ms/step - loss: 7.9052e-04 - accuracy: 1.0000 - val_loss: 9.0972 - val_accuracy: 0.3376\n",
            "Epoch 185/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 8.0482e-04 - accuracy: 1.0000 - val_loss: 9.1008 - val_accuracy: 0.3376\n",
            "Epoch 186/200\n",
            "21/21 [==============================] - 2s 106ms/step - loss: 9.2010e-04 - accuracy: 1.0000 - val_loss: 9.1909 - val_accuracy: 0.3249\n",
            "Epoch 187/200\n",
            "21/21 [==============================] - 2s 108ms/step - loss: 8.0940e-04 - accuracy: 1.0000 - val_loss: 9.2504 - val_accuracy: 0.3249\n",
            "Epoch 188/200\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 7.0901e-04 - accuracy: 1.0000 - val_loss: 9.2240 - val_accuracy: 0.3376\n",
            "Epoch 189/200\n",
            "21/21 [==============================] - 3s 151ms/step - loss: 7.2755e-04 - accuracy: 1.0000 - val_loss: 9.3641 - val_accuracy: 0.3249\n",
            "Epoch 190/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 7.7138e-04 - accuracy: 1.0000 - val_loss: 9.2796 - val_accuracy: 0.3291\n",
            "Epoch 191/200\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 6.9658e-04 - accuracy: 1.0000 - val_loss: 9.3205 - val_accuracy: 0.3376\n",
            "Epoch 192/200\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 6.8666e-04 - accuracy: 1.0000 - val_loss: 9.2487 - val_accuracy: 0.3333\n",
            "Epoch 193/200\n",
            "21/21 [==============================] - 2s 100ms/step - loss: 7.0530e-04 - accuracy: 1.0000 - val_loss: 9.2716 - val_accuracy: 0.3333\n",
            "Epoch 194/200\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 6.4940e-04 - accuracy: 1.0000 - val_loss: 9.3493 - val_accuracy: 0.3418\n",
            "Epoch 195/200\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 6.4305e-04 - accuracy: 1.0000 - val_loss: 9.3810 - val_accuracy: 0.3418\n",
            "Epoch 196/200\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 6.1048e-04 - accuracy: 1.0000 - val_loss: 9.4351 - val_accuracy: 0.3291\n",
            "Epoch 197/200\n",
            "21/21 [==============================] - 2s 104ms/step - loss: 5.9468e-04 - accuracy: 1.0000 - val_loss: 9.3478 - val_accuracy: 0.3249\n",
            "Epoch 198/200\n",
            "21/21 [==============================] - 2s 107ms/step - loss: 6.0441e-04 - accuracy: 1.0000 - val_loss: 9.5224 - val_accuracy: 0.3418\n",
            "Epoch 199/200\n",
            "21/21 [==============================] - 2s 106ms/step - loss: 5.9319e-04 - accuracy: 1.0000 - val_loss: 9.4477 - val_accuracy: 0.3333\n",
            "Epoch 200/200\n",
            "21/21 [==============================] - 3s 163ms/step - loss: 5.8268e-04 - accuracy: 1.0000 - val_loss: 9.5348 - val_accuracy: 0.3291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cnn_augment.hd5')\n"
      ],
      "metadata": {
        "id": "-EVRbgsvmcFu"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = get_pd_data(test_processed_image_annotations)"
      ],
      "metadata": {
        "id": "FvVPivuxcz_e"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([get_pixels(test_images, x) for x in test_df[\"file_name\"]], dtype=np.float32)\n",
        "y_test = np.array(test_df.category_id)"
      ],
      "metadata": {
        "id": "LpEafg6MmY3q"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elJDoLR1oIJj",
        "outputId": "d9fce643-4e84-4f9c-97f5-693bb35cad80"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give me the code to get the classification report of predict vs test\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get the predicted labels\n",
        "predicted_labels = np.argmax(result, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "\n",
        "# Print the report\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJByK8ZAoQOD",
        "outputId": "6537217d-59fd-4a8c-9c9d-958011b3b70c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.29      0.41      0.34        17\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.38      0.40      0.39        30\n",
            "           4       0.00      0.00      0.00        67\n",
            "\n",
            "    accuracy                           0.15       125\n",
            "   macro avg       0.13      0.16      0.15       125\n",
            "weighted avg       0.13      0.15      0.14       125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}